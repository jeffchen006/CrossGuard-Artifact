# AE Reproduction Mapping

This file maps each target in `artifact_evaluation/ae_validation_targets.md` to the scripts/logs that reproduce it (or notes when no script exists).

## Tables to reproduce (required)

### `tables/studyTable_new.tex` (Study table / RQ1 + RQ3)
- Log source: `constraintPackage/functionAccess_FullyOnchainVersion.py` run in CrossGuard mode (`--pruneRuntimeReadOnly --pruneCache --pruneERC20 --pruneRAW`) to generate `final4.txt`.
  - `run.sh` contains the command but writes `final4_p.txt`; `readLog_new.py` expects `final4.txt` unless `--final4` is passed.
- Table extraction/validation: `readLog_new.py --table study` (parses `final4.txt` and compares against `Latex_Tables.txt` via `table_printers.py`).
- Derived stats (e.g., 32/37 unique CFs, exceptions list, ratio summary) are computed from the CSV output; no dedicated script emits those counts directly.

### `tables/ablation_gas_new.tex` (Ablation + Gas + Feedback + Bypassability)
- Log source: `constraintPackage/functionAccess_FullyOnchainVersion.py` with different flags:
  - Baseline: no flags -> `final0.txt`
  - Baseline+RR: `--pruneRuntimeReadOnly` -> `final1.txt`
  - Baseline+RR+RE: `--pruneRuntimeReadOnly --pruneCache` -> `final2.txt`
  - Baseline+RR+RE+ERC20: `--pruneRuntimeReadOnly --pruneCache --pruneERC20` -> `final3.txt`
  - CrossGuard: `--pruneRuntimeReadOnly --pruneCache --pruneERC20 --pruneRAW` -> `final4.txt`
  - CrossGuard+Feedback: add `--pruneParametric2` with 19200/6400/267 -> `final4_9.txt` (3d), `final5.txt` (1d), `final5_1.txt` (1h)
  - `run.sh` includes these commands but writes `*_p.txt` names; the defaults expected by `readLog_new.py` are `final0.txt`..`final5_1.txt`.
- Table extraction/validation: `readLog_new.py --table ablation` (uses `table_printers.py` and `Latex_Tables.txt`).
- Gas overhead comes from the `Total gas overhead:` lines in each `final*.txt` log.
- Bypassability columns in the LaTeX table are not generated by any script in this repo; `table_printers.py` ignores those extra columns, so bypassability counts/list appear to be manual or external.

### `tables/comparison.tex` (CrossGuard vs Trace2Inv)
- Log source: `runTrace2Inv.sh`, which runs `constraintPackage/functionAccess_FullyOnchainVersion_Trace2Inv.py` to produce:
  - `trace2inv0_CrossGuard_woTS_compared.txt`
  - `trace2inv1_CrossGuard_wTS_compared.txt`
- Table extraction/validation: `readLog_new.py --table comparison` (parses the two trace2inv logs and compares to `Latex_Tables.txt`).

### `tables/instrumentation.tex` (Instrumentation mapping)
- No generator script found.
- Closest implementation is in runtime tracking code (e.g., `constraintPackage/functionAccess_FullyOnchainVersion.py`, `parserPackage/parser.py`, `constraintPackage/RAWTree.py`), but the LaTeX table is not produced from code.

## Other key statistics (non-table)

### `sections/evaluation.tex` (dataset composition + setup)
- 100,000 recent txs for AAVE/Lido/Uniswap:
  - `constraintPackage/functionAccess_FullyOnchainVersion.py` truncates `txList` with `txList[-100000:]` when `isPopular` is True (AAVE/Lido/Uniswap).
  - `Benchmarks_Txs/collectCrossContract.py` (`writeTxhistory2`) and `Benchmarks_Traces/Txlist2Trace.py` also cap at 100,000.
- Feedback windows (3 days, 1 day, 1 hour): handled via `--pruneParametric2` values 19200/6400/267 in `constraintPackage/functionAccess_FullyOnchainVersion.py`; `run.sh` uses these values to produce `final4_9.txt`, `final5.txt`, `final5_1.txt`.
- Dataset split 21/8/8 (37 incidents after filtering):
  - Source categories are stored per benchmark in `benchmarkPackage/benchmarks/*.json` (`category` field), and `benchmarkPackage/readFiles.py` can read them.
  - No existing script was found that computes the 21/8/8 split or documents the filtering for trivial/offchain cases.

### `sections/experiments/RQ4-5.tex` (Hyperithm / SphereX comparison)
- CrossGuard overhead + 166-transaction breakdown:
  - `final4.txt` contains `benchmark:  SphereX` with category counts (38 deployer, 127 simple, total 166) and `Total gas overhead` (~0.236%).
  - Produced by `constraintPackage/functionAccess_FullyOnchainVersion.py` (same run as Table 2 CrossGuard config).
- SphereX (Hyperithm) overhead 6.09%:
  - No script/log found in this repo that computes the SphereX baseline overhead; likely external measurement.

### `sections/technical1.tex` (heuristic limitation: Bedrock_DeFi only)
- No direct script found for this claim.
- Can be inferred from the ablation outputs (`final*.txt` + `readLog_new.py` Table 2) where Bedrock_DeFi is the only benchmark that fails under the heuristic assumptions.
